# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

orbs:
  # see https://circleci.com/developer/orbs/orb/circleci/aws-cli
  aws-cli: circleci/aws-cli@2.0.3

commands:

  print_pipeline_id:
    description: Print a pipeline ID
    steps:
      - run: echo $CIRCLE_WORKFLOW_ID

  destroy-environment:
    description: roll back aws infrastructure
    parameters:
      stack_name:
        type: string
    steps:
      - run:
          name: delete aws stack
          command: aws cloudformation delete-stack --stack-name udacity #<< parameters.stack_name >>
          when: on_fail

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
jobs:

  say-hello:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    docker:
      - image: cimg/base:stable
    # Add steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      - checkout
      - run:
          name: "Say hello"
          command: "echo Hello, World!"

  print-hello:
    docker:
      - image: alpine:latest
    steps:
      - run:
          name: "print hello"
          command: "echo hello"

  print-world:
    docker:
      - image: alpine:latest
    steps:
      - run:
          name: "print world"
          command: "echo world"

  print-my-name:
    docker:
      - image: alpine:latest
    steps:
      - run: echo $MY_NAME

  save_hello_world_output:
    docker:
      - image: alpine:latest
    steps:
      - run: echo "hello world from file" > ~/output.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - output.txt

  print_output_file:
    docker:
      - image: alpine:latest
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - run: cat /tmp/workspace/output.txt

  dummy-job:
    docker:
      - image: alpine:latest
    steps:
      - print_pipeline_id

  fail-on-purpose:
    docker:
      - image: alpine:latest
    steps:
      - run: return 1
      - run:
          command: echo job failed
          when: on_fail

  # see https://circleci.com/developer/orbs/orb/circleci/aws-cli
  add-ec2-instances-ip-to-ansible-inventory:
    parameters:
      access-key:
        type: env_var_name
        default: AWS_ACCESS_KEY
      secret-key:
        type: env_var_name
        default: AWS_SECRET_ACCESS_KEY
      region:
        type: env_var_name
        default: AWS_REGION
    executor: aws-cli/default
    steps:
      - checkout
      - aws-cli/setup:
          aws-access-key-id: << parameters.access-key >>
          aws-secret-access-key: << parameters.secret-key >>
          aws-region: << parameters.region >>
      - run:
          name: get and add ec2 instances ip
          command: |
            cat ./ansible/inventory.txt
            echo ------------------------
            chmod ugo+rwx ./ansible/add-ec2-instances-ip-to-inventory.sh
            chmod ugo+rwx ./ansible/get-ec2-instances-ip.sh
            ./ansible/get-ec2-instances-ip.sh
            ./ansible/add-ec2-instances-ip-to-inventory.sh
            echo ------------------------
            cat ./ansible/inventory.txt
            echo ------------------------
      - save_cache:
          paths:
            - ./ansible/inventory.txt
          key: ansible-inventory-{{ .Environment.CIRCLE_WORKFLOW_ID }}

  print-ansible-inventory:
    docker:
      - image: alpine:latest
    steps:
      - restore_cache:
          keys:
            - ansible-inventory-{{ .Environment.CIRCLE_WORKFLOW_ID }}
      - run: cat ./inventory.txt

  create-infrastructure:
    docker:
        - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: set up ec2 instance in AWS with CloudFormation
          command: |
            chmod +x create-stack.sh
            ./create-stack.sh udacity-${CIRCLE_WORKFLOW_ID} template.yaml
      #- run:
       #   name: fail on purpose
        #  command: return 1
      - destroy-environment:
          stack_name: udacity-${CIRCLE_WORKFLOW_ID}

  configure-infrastructure:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: [a3:c7:a2:27:b9:f7:55:c6:97:34:1e:96:0a:8d:22:e8]
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible # install the dependencies for ansible
      - run:
          name: configure server
          command: ansible-playbook -i ./ansible/inventory.txt ./ansible/main-remote.yaml

  smoke-test:
    parameters:
      website:
        type: string
    docker:
      - image: alpine:latest
    steps:
      - run:
          command: |
            apk add --update curl
            if curl -s --head "<< parameters.website >>"
            then
              echo "It worked!"
            else
              echo "It failed!"
              return 1
            fi

  # Executes the bucket.yaml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
  # Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yaml template file.
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yaml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yaml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
      # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
      #- run: aws s3 sync index.html s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete

  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - textfile.txt

  # Executes the cloudfront.yaml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`.
  # Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yaml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yaml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

  # Destroy the previous production version's S3 bucket and CloudFormation stack.
  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous production version's S3 bucket and CloudFormation stack.
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive
          #  aws cloudformation delete-stack --stack-name production-distro
          #  aws cloudformation delete-stack --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7}
          #  aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  my-workflow:
    jobs:
#      - say-hello
#      - print-hello
#      - print-world:
#          requires: [print-hello]
#      - print-my-name
#      - save_hello_world_output
#      - print_output_file:
#          requires: [save_hello_world_output]
#      - dummy-job
#      - fail-on-purpose
#      - add-ec2-instances-ip-to-ansible-inventory
#      - print-ansible-inventory:
#          requires: [add-ec2-instances-ip-to-ansible-inventory]
#      - create-infrastructure
#      - configure-infrastructure
#          requires: [create-infrastructure]
#      - smoke-test:
#          website: www.google666.com

      - create_and_deploy_front_end
      - get_last_deployment_id:
          requires: [create_and_deploy_front_end]
      - promote_to_production:
          requires: [get_last_deployment_id]
      - clean_up_old_front_end:
          requires: [promote_to_production]
